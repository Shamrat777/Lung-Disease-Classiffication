{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1fed4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to rename all image file\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.chdir(r'C:\\Users\\Admin\\OneDrive\\Desktop\\Lung Data\\tuberculosis')\n",
    "# print(os.getcwd())\n",
    "\n",
    "# #Display number with leading zeros\n",
    "\n",
    "# for count, f in enumerate(os.listdir()):\n",
    "# \tf_name, f_ext = os.path.splitext(f)\n",
    "# \tf_name = \"tuberculosis\" + str(count).zfill(5)\n",
    "\n",
    "# \tnew_name = f'{f_name}{f_ext}'\n",
    "# \tos.rename(f, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "95ffe2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Program for resize the images\n",
    "\n",
    "# import PIL\n",
    "# import os\n",
    "# import os.path\n",
    "# from PIL import Image\n",
    "\n",
    "# f = r'C:\\Users\\Admin\\OneDrive\\Desktop\\Lung Data\\tuberculosis'\n",
    "\n",
    "# for file in os.listdir(f):\n",
    "#     f_img = f+\"/\"+file\n",
    "#     img = Image.open(f_img)\n",
    "#     img = img.resize((224,224))\n",
    "#     img.save(f_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f55ed70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clahe for image enhancement\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import glob\n",
    "# import time\n",
    "\n",
    "# input = r'C:\\Users\\Admin\\OneDrive\\Desktop\\Lung Data\\covid'\n",
    "# i = 0\n",
    "# #start = time.time()\n",
    "# for img in glob.glob(input + '/*.jpg'):\n",
    "#     #Test%04i.png\n",
    "#     image = cv2.imread(r'C:\\Users\\Admin\\OneDrive\\Desktop\\Lung Data\\covid\\covid%05i.jpg'%i,0)\n",
    "#     #Creating CLAHE \n",
    "#     clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(10,10))\n",
    "#     #Apply CLAHE to the original image\n",
    "#     image_clahe = clahe.apply(image)\n",
    "#     cv2.imwrite(r'C:\\Users\\Admin\\OneDrive\\Desktop\\Lung Data\\covid\\covid%05i.jpg'%i,image_clahe)\n",
    "#     i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "1daf575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e186af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('C:/Users/Admin/OneDrive/Desktop/Lung Data/')\n",
    "\n",
    "# Get filepaths and labels\n",
    "filepaths = list(image_dir.glob(r'**/*.jpg'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "# Concatenate filepaths and labels\n",
    "image_df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "# Drop GT images\n",
    "image_df = image_df[image_df['Label'].apply(lambda x: x[-2:] != 'GT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff6694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame and reset index\n",
    "image_df = image_df.sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "# Show the result\n",
    "image_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6086e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 20 picture of the dataset with their labels\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(image_df.Filepath[i]))\n",
    "    ax.set_title(image_df.Label[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "8034ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate in train and test data\n",
    "train_df, test_df = train_test_split(image_df, train_size=0.6, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "7ca87153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg19.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad428d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c1455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.VGG19(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6926da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model LungNet22\n",
    "\n",
    "from tensorflow.python.keras.layers.pooling import MaxPool2D\n",
    "from tensorflow.python.keras.layers.core import Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "inputs = pretrained_model.input\n",
    "\n",
    "x = tf.keras.layers.Flatten()(pretrained_model.output)\n",
    "#x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model.summary()\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_images,\n",
    "#     validation_data=val_images,\n",
    "#     epochs=300,\n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.EarlyStopping(\n",
    "#             monitor='val_loss',\n",
    "#             patience=1,\n",
    "#             restore_best_weights=True\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "history = model.fit(\n",
    "          train_images,\n",
    "          epochs = 5,\n",
    "          verbose=1,\n",
    "          validation_data = val_images,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b443a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98123814",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebe5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Display the result\n",
    "print(f'The first 6 predictions: {pred[:6]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 15 picture of the dataset with their labels\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "dfd9a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size \"size\"\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "#     display(Image(cam_path))\n",
    "    \n",
    "    return cam_path\n",
    "    \n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"block5_conv4\"\n",
    "img_size = (224,224)\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45629863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the part of the pictures used by the neural network to classify the pictures\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_path = test_df.Filepath.iloc[i]\n",
    "    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    cam_path = save_and_display_gradcam(img_path, heatmap)\n",
    "    ax.imshow(plt.imread(cam_path))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
